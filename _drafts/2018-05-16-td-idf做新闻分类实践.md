---
layout: post
title: TD-IDF做新闻分类实践
category: 
- Machine Learning
- 技术
---
1. 需求背景
2. 方案分析
3. 实践
4. 效果
5. 微信群

## 需求背景
我所在公司是一家新型投行，通过利用新技术给项目执行提供情报和决策支持。数据和情报挖掘是技术部做的最重要的工作。

数据来源主要是通过第三方采购和全网爬取。第三方采购的都是一些结构化的数据，数据格式和内容千变万化，使用方式也千奇百怪，好处是数据专业性强，质量好，整合容易，不好的地方是灵活性不够，如果遇到没有字段就会很麻烦。除了采购，我们也自己做全网爬取，爬取的好处是目标覆盖率高，可定制性强，实时性可控，不好的地方就是爬来的数据基本上都是非结构化的, 并且，数据内容很难控制。数据从爬取到整理到最终供生产用需要处理非常多的问题，流水线非常长，本文主要分享我们在项目中通过机器学习来对爬取的数据进行分类。我们希望把爬取的内容里面所有M&A相关的内容筛选出来，M&A相关的资讯才是对我们业务最有帮助的内容。


## 方案分析
我们的目标是从所有爬取的内容中找出M&A(并购)相关的资讯。当时有三个可以尝试的方向: 

1. 关键词搜索。 
2. 利用NLP技术来做语义理解然后再分类。
3. 机器学习做文本分类。


###关键词搜索
关键词搜索是最直观的一种方法，简单易实现，很多现成的工具和库都支持关键词搜索，并且非常成熟好用。

缺点和优点一样明显。关键词搜索只做到了词的匹配，没有对文档内容做任何统计和理解，词频和位置信息都直接忽略掉了，它处理的信息量太小，对噪音抗干扰能力差, 对筛选结果也只有0和1两种情况，对于信息分类来说远远不够。

所以这种方案很快放弃。

###NLP进行语义理解然后分类
在放弃关键词搜索之后，我们转向了NLP。因为从人的逻辑思维来讲，NLP最有可能像人一样来理解文本，然后像我们期待的一样进行文本分类，只不过比人类做得更快。

我们投入了一些资源，研究了一些常见的算法，也研究了深度学习的一些东西，还买了显卡和设备。然而最终还是放弃了。

原因简单归纳如下:

1. 我们缺乏NLP的人才，现有的人都没有相关的经验，长远来讲不适合现有的人做这个方面的研究。
2. 尝试过在市场上找NLP的人才，候选人太少了。有经验的愿意出来的更少，愿意来小公司的更少。NLP的人都不便宜，这也没啥好说的. 专业一点的人呢，希望过来就有大团队给他带。
3. NLP投入太庞大了。不仅要有算法，还得要有语料库，还得有配套的实验基础设施。光跑几种常见的算法我们都很难找到好的语料库，我们显然没有实力去自己构建语料库。不得不说，中文语料库建设太落后了！

总结下来，这个方向短期内难见效果，不知道水有多深，放弃。

###TD-IDF
最后，我们转向了TD-IDF. 这种算法相对成熟，也相对容易理解。主要是结合词频(TD)和语料库里面的频率算出一个关键词在文档中的权重, 广泛用于关键词提取。

具体步骤:



#Refs

1. [ 使用scikit-learn工具计算文本TF-IDF值](https://blog.csdn.net/Eastmount/article/details/50323063), 这里面有讲TF-IDF的实践，同时有推荐博客